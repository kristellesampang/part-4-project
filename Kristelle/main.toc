\contentsline {section}{Acknowledgements}{v}{Item.4}%
\contentsline {section}{Glossary of Terms}{vi}{Item.4}%
\contentsline {section}{Abbreviations}{vi}{table.1}%
\contentsline {section}{\numberline {1}Introduction}{1}{section.1}%
\contentsline {subsection}{\numberline {1.1}Motivation}{1}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Problem Statement}{1}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Report Structure}{1}{subsection.1.3}%
\contentsline {section}{\numberline {2}Background}{2}{section.2}%
\contentsline {subsection}{\numberline {2.1}Convolutional Neural Networks (CNN)}{2}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Hardware Acceleration for Machine Learning}{2}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Systolic Array Architecture}{3}{subsection.2.3}%
\contentsline {section}{\numberline {3}Literature Review}{3}{section.3}%
\contentsline {subsection}{\numberline {3.1}Sparsity in Neural Networks}{3}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Rectified Linear Unit (ReLU)}{3}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}Pruning}{4}{subsubsection.3.1.2}%
\contentsline {subsection}{\numberline {3.2}Hardware Architectures for Sparsity}{4}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Power Gating}{4}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Compressed Data Formats}{5}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}Specialised Dataflows and Architectures}{5}{subsubsection.3.2.3}%
\contentsline {section}{\numberline {4}Design and Methodology}{5}{section.4}%
\contentsline {subsection}{\numberline {4.1}System Architecture Overview}{5}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Data Generation and Pre-processing}{5}{subsection.4.2}%
\contentsline {subsubsection}{\numberline {4.2.1}AlexNet Model and Data Extraction}{5}{subsubsection.4.2.1}%
\contentsline {subsubsection}{\numberline {4.2.2}Tiling and .mif File Generation}{5}{subsubsection.4.2.2}%
\contentsline {subsection}{\numberline {4.3}Baseline Systolic Array Architecture}{5}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Dynamic Control Unit for Variable Matrix Sizes}{5}{subsection.4.4}%
\contentsline {subsection}{\numberline {4.5}Sparsity Handling Algorithm}{5}{subsection.4.5}%
\contentsline {section}{\numberline {5}Verification and Results}{5}{section.5}%
\contentsline {subsection}{\numberline {5.1}Testbench and Simulation Environment}{5}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Baseline Performance (Dense Matrices)}{5}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Optimised Performance (Stripped Matrices)}{5}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Performance Analysis}{5}{subsection.5.4}%
\contentsline {section}{\numberline {6}Discussion}{5}{section.6}%
\contentsline {subsection}{\numberline {6.1}Analysis of Results}{5}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Design Trade-offs}{5}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Limitations}{5}{subsection.6.3}%
\contentsline {section}{\numberline {7}Conclusion}{5}{section.7}%
\contentsline {section}{\numberline {8}Future Work}{5}{section.8}%
\contentsline {section}{References}{6}{section.8}%
